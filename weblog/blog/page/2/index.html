
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>My Delusional Dream</title>
  <meta name="author" content="Patrick Wagstrom">

  
  <meta name="description" content="About a year ago I ditched Ubuntu and MythTV on my media center box for Windows 7 Ultimate. To be honest one of the main reasons I did this was for &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://patrick.wagstrom.net/weblog/blog/page/2">
  <link href="/weblog/favicon.png" rel="icon">
  <link href="/weblog/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/weblog/javascripts/modernizr-2.0.js"></script>
  <script src="/weblog/javascripts/ender.js"></script>
  <script src="/weblog/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/weblog/atom.xml" rel="alternate" title="My Delusional Dream" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/weblog/">My Delusional Dream</a></h1>
  
    <h2>Thoughts of a cautious technocrat</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/weblog/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:patrick.wagstrom.net/weblog" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/weblog/">Blog</a></li>
  <li><a href="/weblog/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/weblog/2011/05/10/raid-1-performance-on-windows-7/">Raid 1 Performance on Windows 7</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-05-10T19:44:56-04:00" pubdate data-updated="true">May 10<span>th</span>, 2011</time>
        
        
      </p>
    
  </header>


  <div class="entry-content"><p>About a year ago I ditched Ubuntu and MythTV on my media center box for Windows 7 Ultimate. To be honest one of the main reasons I did this was for NetFlix, but also because I got tired of having to tweak my media center all the time and Windows 7 Media Center just works. Also Windows 7 is smart enough to know how to sleep and wake up from sleep, saving my lots of money over the course of a year.</p>

<p>In order to ensure that I never lose any episodes of high quality television programs, I keep my boot and recorded television programs on a Raid 1 (mirror) set of 2 TB drives. Because all of the data is copied across two different drives in theory it have higher speed reads than a single drive, but lets take a look. I admit this isn&#8217;t the most intelligent of tests, as it&#8217;s simply done using ATTO Disk Benchmark. First, the results for an individual 2TB Samsung drive:</p>

  <figure class='center'>
        <img src="/weblog/media/2011/05/Independent_Overlapped_0.5_to_8192_1GB.png">
        <figcaption>Performance for a single 2TB drive </figcaption>
    </figure>


<p>Next, the performance for a pair of 2TB Samsung drives working in a RAID-1 mirror set:</p>

  <figure class='center'>
        <img src="/weblog/media/2011/05/Mirrored_Overlapped_0.5_to_8192_1GB.png">
        <figcaption>Performance for a mirrored pair of 2TB drives </figcaption>
    </figure>


<p>As we see, there is very little difference between the two. In almost all cases the two setups are within about 10% of each other. There clearly is no intelligence in Windows 7 for spreading reads across multiple drives. One of the major side effects of setting up a RAID 1 is that when something goes wrong you&#8217;ll need to rebuild your mirror. Unfortunately, this seems to happen much more often would be desirable and it often renders the machine nearly unusable. However, contrary to my suspicions, this has nothing to do with massively decreased disk performance:</p>

  <figure class='center'>
        <img src="/weblog/media/2011/05/Resynching_Overlapped_0.5_to_8192_1GB.png">
        <figcaption>Performance of mirrored 2TB drives while resynching </figcaption>
    </figure>


<p>I have no idea what the spike in the middle is for. It&#8217;s clear, however, that the reason for the system bogging down is not because of decreased drive performance but rather because of other issues. This might be CPU related as my media center box is running on a very old AMD Athlon64x2 4400+ on a motherboard that is almost six years old. So, the resynching problems might be because of CPU issues, or it could be because of something else (perhaps CrashPlan is doing something weird). I really have no idea right now.</p>

<p>While I was benchmarking I also decided to benchmark my 1st generation USB drobo with 2x1TB and 2x2TB drives in it. You can see where this going. Performance is atrocious. Glad I use it for backup storage and videos.</p>

  <figure class='center'>
        <img src="/weblog/media/2011/05/Drobo_Overlapped_0.5_to_8192_1GB.png">
        <figcaption>Drobo benchmark performance. You didn&#8217;t think it would be any good, did you? </figcaption>
    </figure>



</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/weblog/2011/04/18/guilty-pleasures/">Guilty Pleasures&#8230;</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-04-18T19:05:59-04:00" pubdate data-updated="true">Apr 18<span>th</span>, 2011</time>
        
        
      </p>
    
  </header>


  <div class="entry-content"><p>I&#8217;m 32, married, a professional scientist, and I have a confession to make. I play video games. Worse, I feel guilty about playing games. I often feel so guilty that it saps much of the guy from the game, turning it into some perverse drudgery where I feel obligated to keep on playing so I can say I actually beat the game. In other words, the guilt that I get from playing video games is so great that it turns every game into an <a href="http://majicjungle.com/blog/261/">obligation game like Farmville</a>.</p>

<p>I shouldn&#8217;t say that it&#8217;s always this way with games. I can sit down and play Hydro Thunder for 15 minutes after work and enjoy it. Until I realize that I should be doing something else, like <a href="http://twentysixandtwo.wordpress.com/">training for a marathon</a>, reading a paper, or writing some code.  What&#8217;s interesting is that nowhere in that list of alternative things is something that is related to family. It could be because I don&#8217;t live with my wife right now and I don&#8217;t have kids. But I believe it&#8217;s a symptom of something else.</p>

<p>Between my masters and doctorate degrees I spent a little over seven years in graduate school. Seven years in which every waking moment was supposed to be optimized for work. Now, I admit that I didn&#8217;t do that. In fact, I had one hell of time during graduate school. It was a hell of a lot of fun. However, graduate school has no concept of work life balance. There always
is more work you can be doing. You know that there is always some paper you should be reading or writing, a presentation that could be created, or a new skill to be obtained. Even if your advisor doesn&#8217;t drill that into your head (and thankfully I had amazing advisors) there are always other students who do.</p>

<p>Of course, it should have gotten better after grad school, but then I left to work for a company that gave up on the concept of work life balance and now talks about work life integration. This is largely a side effect of working with people all over the world. Phone calls from 9-11pm with China are hardly unusual. Nor is a 7:30am meeting with Israel. On the plus side I get the
flexibility I need to travel and can sleep in on days when I don&#8217;t have early morning meetings, but it still remains that during my waking hours I always have a sense of guilt about things I should be doing. In turn this guilt ends up sapping the fun away from things that should be fun.</p>

<p>The question that I need to answer is this, which is the correct behavior? Believing that video games are fun? Realizing there is always more to do? Or perhaps some other choice?</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/weblog/2011/01/01/2011-personal-development-goals/">2011 Personal Development Goals</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-01-01T00:01:15-05:00" pubdate data-updated="true">Jan 1<span>st</span>, 2011</time>
        
        
      </p>
    
  </header>


  <div class="entry-content"><p>I hate the concept of New Year&#8217;s Resolutions with an utter passion. It&#8217;s arbitrary for people to pick a single day and decide to change everything. Some people might call these resolutions, I call these personal development goals.  None of these are dramatic changes from things that I already do, or should be doing. Rather, this set of goals will help keep me on track for 2011.</p>

<h3>Academic</h3>

<ul>
<li>Submit papers to FSE, CSCW, and ICSE</li>
<li>Submit at least one journal paper</li>
</ul>


<h3>Physical</h3>

<p>These and a few more are covered in <a href="http://twentysixandtwo.wordpress.com/2010/12/31/running-goals-for-2011-looking-forward/">a post about 2011 goals on my marathon blog</a>.</p>

<ul>
<li>Run a mile in under 5:50</li>
<li>Run a marathon in under 3:50</li>
<li>Bench press my own weight</li>
<li>Get down to 170 lbs</li>
<li>Barefoot/Vibram race of 10k or more</li>
<li>Run to and from work at least five times</li>
</ul>


<h3>Personal</h3>

<ul>
<li>Release a new and interesting Open Source project</li>
<li>Visit a new country</li>
<li>Read two &#8221;<a href="http://www.bbc.co.uk/arts/bigread/top100.shtml">Classics</a>&#8221;</li>
<li>Win at least two of my existing video games before buying any new ones</li>
<li>Spend less than $60 at the cafeteria at work</li>
<li>Do four &#8220;10 day trials&#8221;</li>
<li><del>Cook Creme Brulee</del> - accomplished on 12/27/2010. That&#8217;s what getting a Creme Brulee torch for Christmas will do for you.</li>
</ul>


<h3>Breaking Bad Habits</h3>

<ul>
<li>Only 12 sodas in the year</li>
<li>Only 6 packs of Starburst in the year</li>
<li>Only 3 visits to McDonalds in the year</li>
</ul>


<p>The most annoying thing about setting such personal development goals is that I haven&#8217;t been able to find a good tool to track these goals.  If anyone knows of one feel free to post it in the comments.  I&#8217;ll revisit these goals at the end of the 2011 calendar year.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/weblog/2010/12/31/open-source-predictions-for-2011/">Open Source Predictions for 2011</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-12-31T20:00:36-05:00" pubdate data-updated="true">Dec 31<span>st</span>, 2010</time>
        
        
      </p>
    
  </header>


  <div class="entry-content"><p>Following on the heels of my <a href="http://patrick.wagstrom.net/weblog/2010/12/31/a-review-of-open-source-predictions-for-2010/">somewhat successful predictions regarding Open Source for 2010</a>, I now my present my 10 predictions for Open Source in 2011.</p>

<ol>
<li><p>On the PC front Netflix will continue to require Silverlight for streaming, although they&#8217;ll finally get their act together and make it work well with GPU acceleration. Interfaces for Netflix will all move the route of the PS3 and adopt an HTML based interface.</p></li>
<li><p>Google will meet it&#8217;s match and discover that the movie and TV studios really don&#8217;t want to work with them and will be forced to pull the plug on Google TV.</p></li>
<li><p>Although Google will continue to tout the number of Android phones available as a success metric for the project, it will continue to see fragmentation and iPhone will remain the phone to beat.</p></li>
<li><p>Despite all of the Android tablets and the upcoming Blackberry Playbook, the iPad will remain dominant and continue to sell more than all the other tablets combined.</p></li>
<li><p>RIM will introduce a new OS for their phones based on the Playbook&#8217;s OS. The OS will be open sourced but will fail to attract any sort of market movement.</p></li>
<li><p>Chromium OS from Google will land like a lead balloon.  Initial reviews of the device will be severely hampered by the inability to access many services without Internet access.</p></li>
<li><p>The browser wars will continue to heat up (hello, 1998!). Firefox&#8217;s market share will remain relatively stagnant while Chrome&#8217;s market share grows. This stagnation will result in some shakeups at Mozilla as they attempt to re-evaluate the market landscape.  This will eventually lead to a new and lighter desktop browser based off Firefox.</p></li>
<li><p>Open Source hardware outside of Android will generally continue to falter. This includes OLPC and the Boxee Box (re-run from last year).</p></li>
<li><p>We&#8217;ll see the first lawsuit regarding ownership of code in an Open Source project after the code of an original author has been patched out and the project license changed (re-run from last year).</p></li>
<li><p>Apache will have a significant long term shakeup regarding their relationship with Java.  I&#8217;d imagine that this means that the Java projects are jettisoned into a new foundation.</p></li>
</ol>


<p>There are a few predictions in this list that are rather ambitious - particularly the creation of a new browser from Mozilla and pulling the plug on Google TV. I was at least partially right on 5/10 predictions last year, I&#8217;m feeling a little more confident this year and saying that I&#8217;ll get 6 correct this year, making me correct more often then not.</p>

<p>What at your thoughts on these predictions?  Too much? Too easy?</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/weblog/2010/12/31/a-review-of-open-source-predictions-for-2010/">A Review of Open Source Predictions for 2010</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-12-31T12:00:46-05:00" pubdate data-updated="true">Dec 31<span>st</span>, 2010</time>
        
        
      </p>
    
  </header>


  <div class="entry-content"><p>As 2009 came to a close and 2010 started I decided to put all of my schooling and research to good use and attempt some short term prognostication. I entered the realm of people making predictions for 2010. Here&#8217;s a recap of <a href="http://patrick.wagstrom.net/weblog/2009/12/31/open-source-predictions-for-2010/">my predictions for 2010</a> and how everything shook out:</p>

<ol>
<li><p><strong>The <a href="http://www.eclipse.org/">Eclipse Foundation</a> will undergo a major upheaval related to community/corporate structure and governance.</strong><br/>
Wrong - As near as I can tell there was no upheaval in the Eclipse Foundation.  The Foundation continues to grow and release some really high quality software.</p></li>
<li><p><strong>Highly customized hardware running on Open Source will continue to under-perform, particularly OLPC and Litl</strong><br/>
Correct - OLPC stayed relatively out of the news this last year.  Most of the talk has focused around the XO-3 that is expected to be revealed at CES 2011. The biggest news that I remember seeing about OLPC is that the display technology was available from Pixel Qi and you could hack it into your netbook.  Very cool, but not what OLPC set out to do.  As for Litl, the only real time I heard about them over the past year was when they sponsored elements of the Boston GNOME Summit.</p></li>
<li><p><strong>No Netflix on Linux</strong><br/>
Correct - This was almost too easy. Next year I&#8217;ll predict that Mac users are smug.</p></li>
<li><p><strong>The Boxee Box will underperform</strong><br/>
Correct - The Boxee Box was delayed because of a switch to an Intel architecture, a decision that makes it very similar to a Google TV device. Complete with the drawbacks of content blocking.  However, somewhat orthogonal, it appears that HTPC and embedded attached devices are still a niche market. Apple made some nice inroads with the new version of Apple TV, but that&#8217;s not open source. Given the tepid reviews of the Boxee Box, I&#8217;d say this was Correct.</p></li>
<li><p><strong>Google will suffer a major privacy problem and be quiet about it</strong><br/>
Mostly Correct - Google did have a bit of a privacy leak, but not quite in the way that I thought.  Google Buzz proved to be a privacy disaster for them and it took them a while to respond.  They were eventually <a href="http://bits.blogs.nytimes.com/2010/11/03/google-settles-suit-over-buzz-and-privacy/">sued over buzz and lost, but no compensation was due to users</a>. I&#8217;d say that I&#8217;m 75% correct on this one, I&#8217;m taking off some because they did respond.</p></li>
<li><p><strong>A major Open Source community will disassociate itself from the Free Software Foundation</strong><br/>
Wrong - I don&#8217;t recall any major Open Source community attempting to disassociate itself from the FSF.</p></li>
<li><p><strong>GNOME&#8217;s reliance on commercial firms will cause a schism and no one will care about GNOME in tablets and phones</strong><br/>
Half Correct - This prediction was sloppy and really should have been two different predictions. It still appears that very few people care about MAEMO/MeeGo.  The Nokia N8 is a niche device that even ubernerds tend to eschew. This doesn&#8217;t appear to have caused many problems for GNOME, however. Therefore, right on one, wrong on another.</p></li>
<li><p><strong>Ubuntu will remove at least one major application and direct users to the cloud.</strong><br/>
Wrong - Nothing of the sort happened.  In retrospect this was a foolish prediction given how Ubuntu pushes itself for rural communities which may have poor network access.</p></li>
<li><p><strong>Rights of Open Source authors will be challenged as a project evolves and code from the original authors no longer exists.</strong><br/>
Wrong - I searched and couldn&#8217;t find any example of such a scenario when the original code from an author has been entirely removed and the license changed. Maybe this is too much of a stretch, or maybe it just didn&#8217;t make enough news.</p></li>
<li><p><strong>At least one major project will transition from the GPL to a more business friendly license</strong><br/>
Wrong - Although every year a handful of smaller projects switch licenses, I don&#8217;t remember seeing any major projects switch from the GPL to a more business friendly license.  If anything, major GPL projects seem to have become stronger in their defense of the GPL (e.g. Wordpress).</p></li>
</ol>


<p>Total score: 3 correct, 1 75% correct, 1 50% correct, 5 wrong. That means five of these came partially true, but if we just add the values, we get 4.25, which means that I wasn&#8217;t a golden prognosticator of Open Source for 2010.  However, on the bright side, at least I was able to test my predictions, <a href="http://spectrum.ieee.org/computing/software/ray-kurzweils-slippery-futurism">unlike Kurzweil</a>, right?</p>

<p>Coming soon I&#8217;ll post my predictions for 2011.  I&#8217;ve learned a little from this analysis and hope to use that knowledge to make some better future predictions.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/weblog/2010/11/24/do-the-tsa-new-ait-body-scanners-hurt-more-than-they-help/">Do the New TSA AIT Body Scanners Hurt More Than They Help?</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-11-24T13:57:03-05:00" pubdate data-updated="true">Nov 24<span>th</span>, 2010</time>
        
        
      </p>
    
  </header>


  <div class="entry-content"><h2>Important</h2>

<p>This report and analysis is still in the draft stage.  I&#8217;m open to new data, criticisms about my model, grammatical/writing fixes, and suggestions about how to make it better. There are three ways to leave me feedback.  You can leave a comment at the end of this post, post a comment on this <a href="http://www.reddit.com/r/OperationGrabAss/comments/eb8s3/hi_reddit_i_did_the_math_and_found_that_tsa/">thread on Reddit</a>, or <a href="http://www.google.com/recaptcha/mailhide/d?k=01d_KRRG_6LhPRiTD9fC4Tjw==&amp;c=MyGA9SW3_9oN5pJPqJPrpR55FWn40q7KpXUM4MUHXoY=">email me directly</a>.</p>

<h2>Pending Improvements</h2>

<p>Thanks to everyone on Reddit, Facebook, and folks in the comments who provided useful feedback.  Here&#8217;s a preliminary list of items that I&#8217;ll address in a revision:</p>

<ul>
<li>Better display of graphs: On the cumulative probability graphs, draw some light lines to show the 10/90 window and the median so individuals are better able to see where these values actually lie.  Also, present an additional graph that shows the distribution of all events to make it obvious what the most likely outcome is.</li>
<li>Non-Normality of Terrorist Attacks: Using the expected value for terrorist attacks is somewhat misleading.  A single successful attack can kill hundreds of people.  Instead, I&#8217;ll write some code to do event based modeling with four different scenarios: 1) Destruction of a cargo airliner (minimal fatalities), 2) Partial destruction of an aircraft (along the lines of a minor/major explosive decompression, like <a href="http://en.wikipedia.org/wiki/Aloha_Airlines_Flight_243">Aloha Airlines flight 243</a>, 3) Complete destruction of a medium - large jet with total loss of life, 4) Major event with multiple cascading destruction and significant ground fatalities.</li>
<li>Driving vs Flying: I probably over-estimated the number of people opting to drive &#8211; it&#8217;s clear that the general public doesn&#8217;t see these things as a major issue (at least that&#8217;s the TSA said, of course, many AIT scanners were off on the day before Thanksgiving).  More likely this should be between 0.25% and 1.0%.  The length of trips should also be better modeled to something like a triangular distribution between with low, most common, and high values of 200, 400, and 700 miles respectively. Even with these numbers, the story will most likely remain the same, the scanners are scaring people away from a safer form of transit in favor of a riskier one.</li>
<li>Subtraction of Other Risks for Drivers: Drivers have slightly lower risk in some areas than flyers, largely because of no radiation exposure at altitude and no risk of non-violent passenger incidents. It&#8217;s going to make a small difference, but should be included for intellectual honesty.</li>
</ul>


<h1>Executive Summary</h1>

<p>The deployment by the <a href="http://www.tsa.gov/">TSA</a> of advanced imaging technology (AIT) consisting of backscatter x-ray and millimeter wave detection devices when combined with the new enhanced pat-down procedures has the potential to reduce violent passenger incidents (aka, terrorist attacks on airplanes).  Given the current deployment levels of AIT scanners, these scanners will over a long time horizon only save approximately 2.4 lives a year, while inducing 3.4 incidents of fatal cancer per year over the same period.  Even more troubling is the increase in fatalities as people choose to drive when faced with the possible option of an intrusive enhanced pat-down, which can result in a median of 189 additional roadway fatalities a year.  All together this means that while the AIT program reduces the incidence of a low likelihood,  high risk and high profile terrorist attack, it induces a median of 190.7 deaths across other parts of American society.  Based on this data alone, the AIT will never be able to save more lives than it costs and the program should be considered a failure and stopped immediately.</p>

<h1>Introduction and Background</h1>

<p>The last few weeks has seen absolute uproar over the new TSA advanced imaging technology (AIT) body scanners. In a nutshell, these devices, which utilize two different technologies allow TSA screeners to see underneath a persons clothing without the need for them to actually remove their clothing.  In fact, as we&#8217;ve seen, trying to be helpful to the TSA and <a href="http://www.signonsandiego.com/news/2010/nov/21/gun-crusader-strips-down-shorts-hauled-out-san-die/">removing your clothing is grounds for arrest</a> (or being told to <a href="http://www.boingboing.net/2010/11/21/my-tsa-stripdown-vid.html">put on a jacket if you&#8217;re a porn star</a>). Concern over these devices comes in multiple different forms: privacy over the use of the images, radiation exposure from backscatter x-ray scanners, and concern over the invasiveness of the new enhanced pat-down procedures for individuals who chose to opt out of the AIT technology or who set off the traditional metal detector too many times.  I believe that all of these are legitimate concerns, however they are far beyond the scope of my expertise.</p>

<p>While there are many questions surrounding AIT, including which airports will be getting them next and what will happen in congress, one thing that I haven&#8217;t seen is a robust analysis of the costs and risks involved in deploying the scanners across the country.  In this post, I&#8217;m going to put the <a href="http://www.epp.cmu.edu/">non-computer science part of my Ph.D.</a> to work and walk through a pretty simple model that allows us to get a first order estimate of the number of lives saved or lost as a result of the AIT body scanners.  In a future post I&#8217;ll go through some of the math on the dollar costs of the body scanners.</p>

<p>Firstly, there is a ton of uncertainty in the science of these scanners and the knowledge of how the public will react.  The fact is that the backscatter x-ray machines do emit radiation, although at very low levels.  The other type of machine, millimeter wave, does not emit radiation. Also, we&#8217;re uncertain about how effective these machines are. They&#8217;re only deployed at a fraction of airports and not all passengers need to go through them.  Even those that go through the scanners cannot be considered 100% effective at stopping a terrorist attack.  Mainly because of well known deficiencies in the scanners, such as their inability to scan body cavities and the fact that <a href="http://www.consumertraveler.com/columns/tsa-myths-and-facts">PETN sewn into the waistband of underwear will not show up on a scanner</a>. Furthermore, the public&#8217;s reaction to these devices is unknown &#8211; will people actually fly less because of the risk of going through a scanner or enhanced pat-down? What all this means is that we can&#8217;t just create a simple set of equations for the model and get a single answer. Instead we need to think in terms of uncertainty and distributions.</p>

<p>There are a variety of great tools that can help us creates models with uncertainty.  Notable is <a href="http://www.lumina.com/ana/whatisanalytica.htm">Analytica</a> from <a href="http://www.lumina.com/">Lumina Decision Systems</a>. Other systems exist, such as Crystal Ball, and a component developed by my team at work, Financier.  As a <a href="http://www.cmu.edu/">CMU</a> student I had access to <a href="http://www.lumina.com/ana/whatisanalytica.htm">Analytica</a>, which would have been perfect for this, but my license expired after I received my doctorate. Financier might have worked, but I wanted to make sure that I&#8217;m 100% clear this analysis was done on my personal time and the opinions of this document do not reflect those of my employer.  No company software or hardware was used.</p>

<p>Instead, I took the basic premises that I needed to know and wrote a very simple simulation engine that handles uncertainty in <a href="http://www.python.org/">Python</a>.  You can <a href="https://github.com/pridkett/TSASimulation">check all of the code from GitHub</a>.  The code documents all of the input variables along with their sources and shows the complete set of equations for the output.  If you&#8217;ve got Python and the <a href="http://pyparsing.wikispaces.com/">pyparsing library</a> installed on your system, you should be good to download and run the simulation.  Stats and graphs were created in <a href="http://www.r-project.org/">R</a>; the script for their generation is included in the archive.</p>

<h1>Model Inputs</h1>

<p>For each of the model inputs, the best information possible was collected.  I should note, that I&#8217;m not an expert on radiation exposure or terrorism, but I do have quite a bit of psychology background and know how to dig at and critically evaluate numbers.</p>

<ul>
<li><p><strong>Value of a Human Life:</strong> $6.9M
<strong>Source:</strong> EPA 2008</p></li>
<li><p><strong>Risk of Dying from a Violent Passenger Incident:</strong> 22 in 1 Billion (per flight)
<strong>Source:</strong> <a href="http://www.schneier.com/blog/archives/2010/01/nate_silver_on.html">Bruce Schneier&#8217;s Analysis of Nate Silver&#8217;s Numbers</a>
I added uncertainty to make this a normal distribution with mean of 22 in 1 billion and standard deviation of 3 in 1 billion.</p></li>
<li><p><strong>Passenger Enplanements:</strong> 621,000,000
<strong>Source:</strong> <a href="http://www.transtats.bts.gov/">http://www.transtats.bts.gov/</a>
This number includes only domestic passengers.  I added uncertainty to create a normal distribution of 10 million passengers a year.  I acknowledge that international traffic increases this, but I haven&#8217;t thought about how to deal with it yet.</p></li>
<li><p><strong>AIT Success Rate:</strong> Uniformly distributed between 0.50 and 0.80
<strong>Source: </strong>My own estimate.
I&#8217;m trying to be optimistic about the success of these devices.  We know there are multiple things they can&#8217;t pick up, like PETN sewn into clothing, so they&#8217;ll never be 100%.</p></li>
<li><p><strong>Percentage of Passengers with AIT Screening:</strong> Uniformly distributed 17% and 40%
<strong>Source: </strong> <a href="http://boardingarea.com/blogs/flyingwithfish/2010/11/23/will-you-encounter-a-tsa-whole-body-scanner-statistically-no/">Steve Frischling contacted the TSA to get the full counts of checkpoints with AIT scanners.</a>
I added uncertainty to this model.  Frischling&#8217;s estimate of 17% is based on uniform passenger distribution across checkpoints.  I assume that passengers are larger airports are more likely to experience them. Therefore, it may be up to 40% of all passengers who have AIT screening as an option.</p></li>
<li><p><strong>Percentage of AIT Devices that are Backscatter:</strong> Uniformly distributed between 30 and 75%
<strong>Source:</strong> <a href="http://www.flyertalk.com/forum/travel-safety-security/1138014-complete-list-airports-whole-body-imaging-advanced-imaging-technology-scanner.html">This thread on FlyerTalk tracks the distribution of the devices and their classification.</a>
However, there have been numerous instances when individuals were mistaken about the type of device and had to update the document.  Therefore, while the page looks about 50/50, I added uncertainty.</p></li>
<li><p><strong>Passenger Exposure per Backscatter Screening:</strong> Uniformly distributed between 0.20µSv and 0.80µSv
<strong>Source:</strong> The <a href="http://blog.tsa.gov/2009/11/response-to-oops-backscatter-x-ray.html">TSA claims</a> backscatter machines max out at below the 0.25µSv limit set by the government.  This claim is countered by the work of<a href="http://www.public.asu.edu/~atppr/RPD-Final-Form.pdf"> Peter Rez at Arizona State University who found they may have a dose of as much as 0.80µSv</a>.  This also does not address recent comments by <a href="http://www.dailymail.co.uk/health/article-1290527/Airport-body-scanners-deliver-radiation-dose-20-times-higher-thought.html">David Brenner of Columbia who believes that the approximately 1:20 people with a specific genetic mutation may be particularly sensitive</a>.</p></li>
<li><p><strong>Risk of Fatal Cancer per µSv of Exposure</strong>: 1/12.5 Million
<strong>Source:</strong> <a href="http://www.slideshare.net/fovak/health-effects-of-radiation-exposure-presentation">Slide 76 of this presentation</a>
The presentation indicates that even a small dose of radiation may cause fatal cancer and that the response is roughly linear.  I extrapolated from the lowest level of radiation exposure on chart 76.  If someone has a better set of data for this, I&#8217;ll gladly take it. I added uncertainty to make this a normal distribution with a mean of 1/12.5 million and standard deviation of 1/125 million.</p></li>
<li><p><strong>Fight Distance:</strong> 500 miles
<strong>Source</strong>: My own estimate
The average distance for which an individual would be willing to drive over taking a flight. I based this on my cutoff line.  Admittedly, I&#8217;ve driven from Pittsburgh to Austin, TX in one shot and have routinely driven 18 hours in a day before.</p></li>
<li><p><strong>Percentage of Passengers Driving:</strong> Uniformly distributed between 0.5% and 5%
<strong>Source:</strong> My own estimate, based loosely off various non-scientific polls.
I actually believe that this number skews more toward the lower end.  If anyone can come up with a better value, let me know.</p></li>
<li><p><strong>Fatalities per Mile of Driving:</strong> 1.13/100 Million Miles
<strong>Source:</strong> <a href="http://www-fars.nhtsa.dot.gov/Main/index.aspx">http://www-fars.nhtsa.dot.gov/Main/index.aspx</a>
Because this number is likely to fluctuate some each year, although it has generally been going down, I&#8217;ve modeled this as a normal with a mean of 1.13/100 Million and standard deviation of 0.1/100 Million Miles.</p></li>
</ul>


<h1>Model</h1>

<p>In brief, the model estimates the number of additional lives saved or lost because of AIT screening technology.  Lives can be saved by a reduction in the number of fatalities from violent passenger incidents. Lives can be lost by an increase in the number of people driving and an increase in fatal cancers because of backscatter radiation.</p>

<ul>
<li><p><strong>Number of Passengers Driving:</strong> Passenger Enplanements * Percentage of Passengers Driving
This is how man additional people will be on the road because of opting out of flying altogether.</p></li>
<li><p><strong>Number New Driving Fatalities:</strong> Number of Passengers Driving * Flight Distance * 2 * Fatalities per Mile
The distance is multiplied by two here because passengers will need to drive both directions to their destination.</p></li>
<li><p><strong>Expected VPI Fatalities:</strong> Risk of Dying from a Violent Passenger Incident * Passenger Enplanements
This is the current baseline number of fatalities expected in a given year.</p></li>
<li><p><strong>Expected AIT VPI Fatalities:</strong> Risk of Dying from a Violent Passenger Incident * (1 - AIT Success Rate) * Passenger Enplanements * Percentage of Passengers with AIT Screening + Risk of Dying from a Violent Passenger Incident * Passenger Enplanements * (1 - Percentage of Passengers with AIT Screening)
AIT scanners are only effective where they are used.  This model assumes that the risk of a passenger initiating a VPI has not changed for those passengers not going through AIT.</p></li>
<li><p><strong>Expected Cancer Fatalities:</strong> Passenger Enplanements * Percentage of Passengers with AIT Screening * Percentage of AIT Devices that are Backscatter * Passenger Exposure per Backscatter Screening * Risk of Cancer per &amp;microSv of Exposure
As there is no safe level of radiation exposure, even a small amount can cause cancer.  Here we assume that only those passengers who are exposed to AIT backscatter screening are subject to an increase in their cancer risk.  We do not take into account the inherent increase in radiation from flying as that doesn&#8217;t change. For purposes of simplicity, we also ignore the number of individuals who choose to drive.</p></li>
<li><p><strong>Increase in Fatalities due to AIT:</strong> Number New Driving Fatalities + Expected Cancer Fatalities - (Expected VPI Fatalities - Expected AIT VPI Fatalities)
The total number of new deaths represented in the model minus the expected benefit from AIT.</p></li>
</ul>


<h1>Model Outcomes</h1>

<p>The model was run through 10000 iterations to produce a range of outcomes.  First, we&#8217;ll start with the expected current number of fatalities from violent passenger incidents.  The skies over the United States have been safe from these incidents since 9/11, so this may be overstating the effect. According to my model the median number of passenger fatalities from VPIs on domestic flights is about 13.7 a year, with a 10/90 confidence window of 11.3-16.1 fatalities a year.  <a href="http://en.wikipedia.org/wiki/Boeing_737">A Boeing 737 seats around 162 passengers</a>, so this means one VPI resulting in total loss of all passengers on a Boeing 737 sized plane ever 12-13 years.</p>

  <figure class='center'>
        <img src="/weblog/media/2010/11/expected_vpi_fatalities.png">
        <figcaption>Expected Fatalities from Violent Passenger Incidents (VPIs) </figcaption>
    </figure>


<p>With the introduction of the AIT devices at their current deployment levels, the median expected number of fatalities from VPIs is down to 11.1 a year, with a 10/90 confidence window of 9.0-13.3 fatalities a year.</p>

  <figure class='center'>
        <img src="/weblog/media/2010/11/expected_ait_vpi_fatalities.png">
        <figcaption>Expected Fatalities from VPI with AIT in Place </figcaption>
    </figure>


<p>It&#8217;s quickly apparent there there is little difference between these values.  With AIT there is a median improvement of 2.44 fatalities a year, and even in the best case out of the 10,000 simulations only 6.2 additional lives were saved per year.  From a purely monetary perspective, using the EPA&#8217;s value of $6.9M/life, the AIT project saves $16.84M a year.  I&#8217;m almost certain that the program will cost more than from a strict dollar perspective.</p>

<p>Next, lets examine the increased risk of cancer from these devices.  It&#8217;s believed that any exposure to radiation, no matter how small the dose, increases the chance of cancer.  The TSA has pointed out that under their specifications, backscatter x-ray machines emit about the same amount of radiation as two minutes of flying time (about 0.2µSv).  However, as stated, physics professor Peter Rez has calculated that the likely exposure from a functioning machine is much greater. Using the data from Professor Rez along with known exposure guidelines and the uncertainty in the model, we see there is a median of 3.4 additional cancer fatalities per year, and a 10/90 confidence window of 1.5 to 6.3. The maximum number of new cancer fatalities 11.6/yr. This increase in cancer alone outweighs the median number of lives saved from AIT scanning.</p>

  <figure class='center'>
        <img src="/weblog/media/2010/11/expected_cancer_ait_fatalities.png">
        <figcaption>Expected Fatalities from Cancer as a Result of Radiation From Backscatter X-Rays </figcaption>
    </figure>


<p>However, there is a slightly more insidious and much more dangerous factor in play.  The mere presence of AIT technology in airports and the possible consequences of an enhanced pat-down will lead some to choose to drive rather than fly.  While there have been some reports that show that as many as 20% [citation needed] of people will reconsider flying because of the enhanced pat-down, I considered the estimates to be far lower.  In my model, the median number of people driving was about 17,000,000 with a 10/90 confidence window of 5,800,000 to 28,500,000.  These numbers may seem a little high, but that&#8217;s only about 2% of flights being exchanged for a drive of around 500 miles.  Roughly equivalent to a family deciding to drive from Chicago to Minneapolis for Christmas.</p>

  <figure class='center'>
        <img src="/weblog/media/2010/11/expected_passengers_driving.png">
        <figcaption>Expected Number of Passengers Choosing to Drive instead of Fly </figcaption>
    </figure>


<p>Unfortunately, driving is a much riskier endeavor than flying.  In fact, you&#8217;re more likely to be killed driving to the airport than you are on a plane. Of these people making 1000 mile long round trips, it&#8217;s likely that we&#8217;ll see about 189 new fatalities with 10/90 confidence window of 65.6 to 321.3 fatalities.  This is a grim picture, indeed.</p>

  <figure class='center'>
        <img src="/weblog/media/2010/11/expected_driving_fatalities.png">
        <figcaption>Expected Fatalities from Passengers Choosing to Drive Instead of Flying </figcaption>
    </figure>


<p>Finally, we can take the complete picture; the benefit of the AIT machines versus the increased deaths from driving and cancer and see the total increase in fatalities.  In this case, it&#8217;s not pretty at all.  The use of AIT machines and enhanced pat-downs, when combined with their associated stigma can be expected to cause an additional 190 deaths a year with 10/90 confidence window 67 to 323.  That&#8217;s the equivalent of all the passengers on a 737 and then some EVERY YEAR as a result of the AIT scanning devices.</p>

  <figure class='center'>
        <img src="/weblog/media/2010/11/expected_ait_fatality_increase.png">
        <figcaption>Expected Increase in Fatalities as a Result of AIT Scanning </figcaption>
    </figure>


<h1>Shortcomings</h1>

<p>One of the problems with pinpointing deaths is that massive deaths at the same time have a significantly greater impact on public perception than a large amount of distributed deaths that aren&#8217;t always directly attributable.  For example, emissions from coal fired power plants kill significant numbers of people and yet most people are much more scared of nuclear plants because of their potential for an extremely high risk, yet low probability event.  When these events happen react in such a way that the impact is magnified.  More directly, the 9/11 terrorist attacks caused tens of thousands of Americans to cancel their travel plans and businesses to delay investment, which contributed to sending a shaky economy into recession.  This despite the fact that the number of people killed in the attacks was roughly the same number of people killed in a month in traffic accidents across the country or the number of people killed by cancer and heart disease on a DAILY basis. I have no doubt that even the bombing of a cargo flight, with minimal loss to human life, will have a significant and detrimental effect to the American economy, which this simulation cannot model.</p>

<p>This model also does little to address the costs of the screening.  There is not only the cost of the screening devices, but also training of employees, reconfiguration of checkpoints, loss of time for travelers, and treatment for cancer induced by backscatter x-ray.  A robust model would include these, but there is little doubt that the result will remain the same.</p>

<h1>Conclusion</h1>

<p>The overall risk of deploying AIT scanners is significant given their potential benefit.  An median increase of 190 deaths per year can be expected as the result of increases in cancer from screening and increased road fatalities from people opting out of flying and driving to their destination.  From a pure human life perspective, the AIT proposition is a failure.  Even discounting the fatalities from driving, at current deployment levels AIT devices can be expected to induce 3.3 additional cases of cancer a year while only saving 2.4 additional lives per year. Elimination of the backscatter devices and replacement with millimeter wave detection devices may prove to be a suitable replacement given these substantial health risks.</p>

<h1>Next Steps</h1>

<p>I still consider this analysis in a draft form.  As I can find better information I&#8217;ll update the model.  If you have suggestions on ways to improve the analysis please leave them in the comments.  After I feel that this has been properly vetted, I&#8217;m going to send this to <a href="http://klobuchar.senate.gov/">my</a> <a href="http://franken.senate.gov/">senators</a> and <a href="http://ellison.house.gov/">congressman</a> &#8211; all of which are generally pretty awesome.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/weblog/2010/03/03/acm-sigs-style-for-zotero/">ACM SIGS Style for Zotero</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-03-03T14:33:53-05:00" pubdate data-updated="true">Mar 3<span>rd</span>, 2010</time>
        
        
      </p>
    
  </header>


  <div class="entry-content"><p>Academics live and die based on references. A variety of tools exist to manage references, from the sadly ubiquitous <a href="http://www.endnote.com/">EndNote</a>, to manually curated <a href="http://www.bibtex.org/">BibTeX</a> files, to some people who just type their entries by hand with each paper. A variety of web aware citation management tools are also available, for example <a href="http://www.mendeley.com/">Mendeley</a> and <a href="http://www.zotero.org/">Zotero</a>.</p>

<p>For the past few years I&#8217;ve been using Zotero and have found it to be wonderful (with a few slight exceptions). It lives inside of Firefox and provides one click functionality to add a reference to my database and synchronize the change across computers automagically. It has good plugins for Microsoft Word and OpenOffice to provide citation management on a level that is similar to what one gets on EndNote. It also supports BibTeX export (with some slight key naming issues).</p>

<p>Unfortunately, almost every journal and conference wants slightly different formatting for their references. Zotero can handle this through the use of style files crafted in the <a href="http://xbiblio.sourceforge.net/csl/">Citation Style Language (CSL)</a>. I had noticed that my submission to <a href="http://www.sbs.co.za/ICSE2010/">ICSE 2010</a> was dinged because I had the citations in the wrong format &#8211; apparently I was mistaken and thought they used SIGCHI reference formatting, when in fact they use ACM SIGS reference formatting. Sadly, Zotero doesn&#8217;t have a style for formatting ACM SIGS references, until now. While finishing up <a href="https://sites.google.com/a/wagstrom.net/academic/publications/Williams_2010_SupportingEnterpriseStakeholdersInSoftwareProjects.pdf?attredirects=0&amp;d=1">my paper on supporting stakeholders in enterprise software projects</a> for the <a href="http://www.itu.dk/people/ydi/CHASE2010.html">CHASE 2010</a> workshop I decided it would be easier to bite the bullet and just write my own style that fits the specification.  I don&#8217;t claim that the style is complete, but it seems to work well enough.  You can find the style <a href="http://gist.github.com/320873">hosted as a GitHub gist</a>, an I&#8217;ve also embedded the file below. If you&#8217;re using Zotero you&#8217;ll need to download the raw file then drag it into Zotero where the style will be installed and you&#8217;ll now see ACM SIGS as an option for reference formatting.  Feel free to fork it and improve the formatting. In case the embed does not show up, please visit <a href="http://gist.github.com/320873">http://gist.github.com/320873</a> instead.</p>

<div><script src='https://gist.github.com/320873.js?file='></script>
<noscript><pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;?oxygen RNGSchema=&quot;http://xbiblio.svn.sourceforge.net/viewvc/*checkout*/xbiblio/csl/schema/trunk/csl.rnc&quot; type=&quot;compact&quot;?&gt;
&lt;style xmlns=&quot;http://purl.org/net/xbiblio/csl&quot; class=&quot;in-text&quot; xml:lang=&quot;en&quot;&gt;
  &lt;info&gt;
    &lt;title&gt;ACM SIGS&lt;/title&gt;
    &lt;id&gt;http://www.zotero.org/styles/acm-sigs&lt;/id&gt;
    &lt;link href=&quot;http://gist.github.com/gists/320873&quot;/&gt;
    &lt;author&gt;
      &lt;name&gt;Michael Berkowitz&lt;/name&gt;
      &lt;email&gt;mberkowi@gmu.edu&lt;/email&gt;
    &lt;/author&gt;
    &lt;contributor&gt;
      &lt;name&gt;Julian Onions&lt;/name&gt;
      &lt;email&gt;julian.onions@gmail.com&lt;/email&gt;
    &lt;/contributor&gt;
    &lt;contributor&gt;
      &lt;name&gt;Rintze Zelle&lt;/name&gt;
      &lt;uri&gt;http://forums.zotero.org/account/831/&lt;/uri&gt;
    &lt;/contributor&gt;
    &lt;contributor&gt;
      &lt;name&gt;Patrick Wagstrom&lt;/name&gt;
      &lt;email&gt;patrick@wagstrom.net&lt;/email&gt;
      &lt;uri&gt;http://academic.patrick.wagstrom.net/&lt;/uri&gt;
    &lt;/contributor&gt;
    &lt;category term=&quot;engineering&quot;/&gt;
    &lt;category term=&quot;generic-base&quot;/&gt;
    &lt;category term=&quot;numeric&quot;/&gt;
    &lt;updated&gt;2010-03-02T16:00:00+00:00&lt;/updated&gt;
    &lt;link href=&quot;http://www.acm.org/sigs/publications/proceedings-templates&quot; rel=&quot;documentation&quot;/&gt;
  &lt;/info&gt;
  &lt;macro name=&quot;author&quot;&gt;
    &lt;names variable=&quot;author&quot;&gt;
      &lt;name initialize-with=&quot;.&quot; delimiter=&quot;, &quot; and=&quot;text&quot; name-as-sort-order=&quot;all&quot;/&gt;
      &lt;label form=&quot;short&quot; prefix=&quot;, &quot; text-case=&quot;lowercase&quot; suffix=&quot;.&quot;/&gt;
      &lt;substitute&gt;
        &lt;names variable=&quot;editor&quot;/&gt;
        &lt;names variable=&quot;translator&quot;/&gt;
      &lt;/substitute&gt;
    &lt;/names&gt;
  &lt;/macro&gt;
  &lt;macro name=&quot;editor&quot;&gt;
    &lt;names variable=&quot;editor&quot;&gt;
      &lt;name initialize-with=&quot;.&quot; delimiter=&quot;, &quot; and=&quot;text&quot; name-as-sort-order=&quot;all&quot;/&gt;
      &lt;label form=&quot;short&quot; prefix=&quot;, &quot; text-case=&quot;lowercase&quot; suffix=&quot;.&quot;/&gt;
    &lt;/names&gt;
  &lt;/macro&gt;
  &lt;macro name=&quot;title&quot;&gt;
    &lt;choose&gt;
      &lt;if type=&quot;book&quot;&gt;
        &lt;text variable=&quot;title&quot; font-style=&quot;italic&quot; text-case=&quot;title&quot;/&gt;
      &lt;/if&gt;
      &lt;!-- ACM SIGS does not quote paper names --&gt;
      &lt;else&gt;
        &lt;text variable=&quot;title&quot; text-case=&quot;sentence&quot;/&gt;
      &lt;/else&gt;
    &lt;/choose&gt;
  &lt;/macro&gt;
  &lt;!-- changes made to publisher formatting, publisher then place --&gt;
  &lt;macro name=&quot;publisher&quot;&gt;
    &lt;text variable=&quot;publisher&quot; suffix=&quot;, &quot;/&gt;
    &lt;text variable=&quot;publisher-place&quot; suffix=&quot;, &quot;/&gt;
    &lt;date variable=&quot;issued&quot;&gt;
      &lt;date-part name=&quot;year&quot;/&gt;
    &lt;/date&gt;
  &lt;/macro&gt;
  &lt;macro name=&quot;access&quot;&gt;
    &lt;text variable=&quot;URL&quot;/&gt;
  &lt;/macro&gt;
  &lt;macro name=&quot;page&quot;&gt;
    &lt;group&gt; 
      &lt;label variable=&quot;page&quot; form=&quot;short&quot; suffix=&quot;. &quot;/&gt;
      &lt;text variable=&quot;page&quot;/&gt;
    &lt;/group&gt;
  &lt;/macro&gt;
  &lt;citation&gt;
    &lt;option name=&quot;et-al-min&quot; value=&quot;3&quot;/&gt;
    &lt;option name=&quot;et-al-use-first&quot; value=&quot;1&quot;/&gt;
    &lt;option name=&quot;collapse&quot; value=&quot;citation-number&quot;/&gt;
    &lt;sort&gt;
      &lt;key variable=&quot;citation-number&quot;/&gt;
    &lt;/sort&gt;
    &lt;layout prefix=&quot;[&quot; suffix=&quot;]&quot; delimiter=&quot;,&quot;&gt;
      &lt;text variable=&quot;citation-number&quot;/&gt;
    &lt;/layout&gt;
  &lt;/citation&gt;
  &lt;bibliography&gt;
    &lt;option name=&quot;entry-spacing&quot; value=&quot;0&quot;/&gt;
    &lt;option name=&quot;second-field-align&quot; value=&quot;true&quot;/&gt;
    &lt;!-- for the most part, ACM SIGS follows IEEE with the exception of the
         sorting of the bibliography --&gt;
    &lt;sort&gt;
      &lt;key macro=&quot;author&quot;/&gt;
      &lt;key variable=&quot;issued&quot;/&gt;
    &lt;/sort&gt;
    &lt;layout suffix=&quot;.&quot;&gt;
      &lt;text variable=&quot;citation-number&quot; prefix=&quot;[&quot; suffix=&quot;]&quot;/&gt;
      &lt;text variable=&quot;type&quot;/&gt;
      &lt;text macro=&quot;author&quot; prefix=&quot; &quot; suffix=&quot;. &quot;/&gt;
      &lt;choose&gt;
        &lt;!-- SIGS Book Formatting --&gt;
        &lt;!-- 95% certain this is correct --&gt;
        &lt;if type=&quot;book&quot;&gt;
          &lt;text macro=&quot;title&quot; suffix=&quot;. &quot;/&gt;
          &lt;group delimiter=&quot;, &quot;&gt;
            &lt;text macro=&quot;publisher&quot;/&gt;
          &lt;/group&gt;
        &lt;/if&gt;
        &lt;!-- SIGS Conference Paper Formatting --&gt;
        &lt;!-- 95% certain this is correct --&gt;
        &lt;else-if type=&quot;paper-conference&quot;&gt;
          &lt;text macro=&quot;title&quot; suffix=&quot;. &quot;/&gt;
          &lt;group delimiter=&quot;, &quot; suffix=&quot;. &quot;&gt;
            &lt;text variable=&quot;container-title&quot; font-style=&quot;italic&quot; prefix=&quot;In &quot;/&gt;
            &lt;text variable=&quot;page&quot; prefix=&quot;pages &quot;/&gt;
          &lt;/group&gt;
          &lt;text variable=&quot;publisher&quot; suffix=&quot;, &quot;/&gt;
          &lt;date variable=&quot;issued&quot; suffix=&quot;.&quot;&gt;
            &lt;date-part name=&quot;month&quot; suffix=&quot; &quot;/&gt;
            &lt;date-part name=&quot;year&quot;/&gt;
          &lt;/date&gt;          
        &lt;/else-if&gt;
        &lt;!-- SIGS Book Chapter Formatting --&gt;
        &lt;!-- 50% certain this is correct --&gt;
        &lt;else-if type=&quot;chapter&quot;&gt;
          &lt;text macro=&quot;title&quot; suffix=&quot;. &quot;/&gt;
          &lt;group delimiter=&quot;, &quot; suffix=&quot;. &quot;&gt; 
            &lt;text variable=&quot;container-title&quot; font-style=&quot;italic&quot; prefix=&quot;In &quot;/&gt;
            &lt;text variable=&quot;page&quot; prefix=&quot;pages &quot;/&gt;
          &lt;/group&gt;
          &lt;!-- &lt;text macro=&quot;editor&quot;/&gt; --&gt;
          &lt;text macro=&quot;publisher&quot;/&gt;
        &lt;/else-if&gt;
        &lt;else-if type=&quot;patent&quot;&gt;
          &lt;text macro=&quot;title&quot; suffix=&quot;, &quot;/&gt;
          &lt;text variable=&quot;number&quot; prefix=&quot;U.S. Patent &quot;/&gt;
          &lt;date variable=&quot;issued&quot; prefix=&quot;, &quot;&gt;
            &lt;date-part name=&quot;month&quot; suffix=&quot; &quot;/&gt;
            &lt;date-part name=&quot;day&quot; suffix=&quot;, &quot;/&gt;
            &lt;date-part name=&quot;year&quot;/&gt;
          &lt;/date&gt;
        &lt;/else-if&gt;
        &lt;else-if type=&quot;thesis&quot;&gt;
          &lt;group delimiter=&quot;, &quot;&gt;
            &lt;text macro=&quot;title&quot;/&gt;
            &lt;text variable=&quot;genre&quot;/&gt;
            &lt;text variable=&quot;publisher&quot;/&gt;
            &lt;date variable=&quot;issued&quot;&gt;
              &lt;date-part name=&quot;year&quot;/&gt;
            &lt;/date&gt;
          &lt;/group&gt;   
        &lt;/else-if&gt;
        &lt;!-- SIGS Journal Formatting --&gt;
        &lt;!-- 95% certain this is correct --&gt;
        &lt;else-if type=&quot;article-journal&quot;&gt;
          &lt;text macro=&quot;title&quot; suffix=&quot;. &quot;/&gt;
          &lt;text variable=&quot;container-title&quot; form=&quot;short&quot; font-style=&quot;italic&quot; suffix=&quot;, &quot;/&gt;
          &lt;text variable=&quot;volume&quot;/&gt;
          &lt;text variable=&quot;issue&quot; prefix=&quot;(&quot; suffix=&quot;)&quot;/&gt;
          &lt;text variable=&quot;page&quot; prefix=&quot;:&quot; suffix=&quot;, &quot;/&gt;
          &lt;date variable=&quot;issued&quot; suffix=&quot;.&quot;&gt;
            &lt;date-part name=&quot;month&quot; suffix=&quot; &quot;/&gt;
            &lt;date-part name=&quot;year&quot;/&gt;
          &lt;/date&gt;          
        &lt;/else-if&gt;
        &lt;!-- SIGS Webpage Formatting --&gt;
        &lt;!-- 90% certain this is correct --&gt;
        &lt;else-if type=&quot;webpage&quot;&gt;
          &lt;text macro=&quot;title&quot; suffix=&quot;. &quot;/&gt;
          &lt;text variable=&quot;URL&quot; suffix=&quot; &quot;/&gt;
          &lt;date variable=&quot;issued&quot; suffix=&quot;.&quot;&gt;
            &lt;date-part name=&quot;month&quot; suffix=&quot; &quot;/&gt;
            &lt;date-part name=&quot;year&quot;/&gt;
          &lt;/date&gt;          
        &lt;/else-if&gt;
    &lt;!-- Default Categorization --&gt;
    &lt;!-- Anything that makes it here should be validated as it's probably incorrectly formatted --&gt;
        &lt;else&gt;
          &lt;!-- &lt;text value=&quot;[[DEFAULT]]&quot;/&gt; --&gt;
          &lt;text macro=&quot;title&quot; suffix=&quot;. &quot;/&gt;
          &lt;group delimiter=&quot;, &quot;&gt; 
            &lt;text variable=&quot;container-title&quot; font-style=&quot;italic&quot;/&gt;
            &lt;text variable=&quot;volume&quot; prefix=&quot; vol. &quot;/&gt;
            &lt;date variable=&quot;issued&quot;&gt;
              &lt;date-part name=&quot;month&quot; form=&quot;short&quot; suffix=&quot;. &quot;/&gt;
              &lt;date-part name=&quot;year&quot;/&gt;
            &lt;/date&gt;
            &lt;text macro=&quot;page&quot;/&gt;
          &lt;/group&gt;
        &lt;/else&gt;
      &lt;/choose&gt;
    &lt;/layout&gt;
  &lt;/bibliography&gt;
&lt;/style&gt;</code></pre></noscript></div>



</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/weblog/2010/02/17/dell-inspiron-zino-hd-and-failure/">Dell Inspiron Zino HD and Failure</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-02-17T14:40:15-05:00" pubdate data-updated="true">Feb 17<span>th</span>, 2010</time>
        
        
      </p>
    
  </header>


  <div class="entry-content"><p>Around work and with friends I&#8217;ve obtained a reputation as the go-to-guy for computer hardware, particular home theater and media center computers. I was really excited about the new Dell Inspiron Zino HD, a tiny little box that can pack a dual core Athlon processor, a couple of gigs of ram, and a decent enough video card to play some games. Starts around $299, and you can get a nicely loaded one for $500. Sounds like a great deal.</p>

<p>A couple of weeks ago I placed an order for an Inspiron Zino HD for my wife and our apartment in Minneapolis. I ordered minor upgrades to make it a bit beefier and faster:</p>

<ul>
<li>AMD Athlon x2 6850</li>
<li>3GB Ram</li>
<li>ATI Radeon HD 4330/512MB RAM video card</li>
<li>320GB hard disk</li>
<li>Dell 1520 802.11 b/g/n wireless card</li>
</ul>


<p>None of these require substantial modifications to the device.  Apparently adding in the video card requires a swap from the standard motherboard to one with an <a href="http://en.wikipedia.org/wiki/Mobile_PCI_Express_Module">MXM</a> video card slot, but that&#8217;s it.</p>

  <figure class='center'>
        <img src="/weblog/media/2010/02/inspiron-zino-hd.jpg">
        <figcaption>My Former Future HTPC </figcaption>
    </figure>


<p>The order was placed on January 31st with an expected delivery date of February 15th thanks to some extra money I paid for expedited shipping.  This was just in time for my monthly visit to Minneapolis where I could set the machine up with Windows 7 Media Center and put it on the wireless network so my wife wouldn&#8217;t need to worry about a thing. To surprise her I also ordered her an HD HomeRun and a nice Windows Media Center remote from Amazon. Instead of using Hulu for everything, she would be able to record everything and not have to wait until the next day to watch shows. This is a godsend to our relationship where otherwise I know that I can&#8217;t call her between 8pm and 10pm EST on Thursdays because of &#8220;30 Rock&#8221; and &#8220;The Office&#8221;.</p>

<p>Toward the middle of last week I started to get concerned.  My order was still listed as &#8220;In Production&#8221;.  On Thursday, the day the machine would have to ship to make it&#8217;s delivery date.  As expected, however, on Friday the website was updated saying that the order was delayed. On Monday afternoon, more than 72 hours after the order was delayed on the website, I finally got an email telling me the order was delayed.  Apparently the tubes are really clogged at Dell.</p>

<p>Yesterday and today I took some time and investigated how many other people had delays and what my other options for.  Some people were advocating the Dell Studio Slim; it looks promising, but it doesn&#8217;t ship until the end of March. Wow. Looking around more I found numerous tales of people who ordered their systems as far back as November and still haven&#8217;t received them:</p>

<ul>
<li><a href="http://en.community.dell.com/forums/p/19310185/19648514.aspx">A retired Librarian&#8217;s tale on dell.com</a></li>
<li><a href="http://me-and-dee.web.officelive.com/ZinoHDReview.aspx">Leon Lin, who ordered a Zino in November with Blu-Ray and still hasn&#8217;t received it</a></li>
<li><a href="http://episteme.arstechnica.com/eve/forums/a/tpc/f/67909965/m/920002762041">RobN from ArsTechnica who ordered one for Christmas and found out it would be substantially delayed</a></li>
<li><a href="http://www.avsforum.com/avs-vb/showthread.php?t=1202126">Hundreds of posts from AVSForum</a></li>
</ul>


<p>Apparently Dell was insistent on giving 1980&#8217;s order from TV commercials a good name by shipping products not in 6-8 weeks, but in 12+ weeks. In some cases they were actually in violation of FTC standards for how long it was taking to ship products.  Awesome. I knew I had to do something to stop the pain now.</p>

<p>At first I called Dell just to try and get a refund for my expedited shipping. After about ten minutes I finally reached a human in India who asked me what my problem was. I stated very clearly that my order was delayed and therefore I should get a refund for the difference in shipping costs. I was transferred and put on hold for another 10 minutes until I spoke to a nice lady named Priyanka. Unfortunately, she didn&#8217;t understand why this would be a problem and said that they could not change my shipping option now that my system was &#8220;in production&#8221;.  I told it had been &#8220;in production&#8221; for the last two and a half weeks, so I&#8217;m sure she could. No dice.</p>

<p>I attempted to figure out what that issue was. Rumors on the webternets indicate that there is a <a href="http://en.community.dell.com/forums/t/19310185.aspx?PageIndex=2#19620350">lack of black lids for this little guy</a>.  Priyanka didn&#8217;t know about that. I asked if she could change my order to a red lid and if things might ship faster, she said that I&#8217;d have to pay the difference in prices. I explained that if I didn&#8217;t get the red lid that I&#8217;d probably just cancel the order, so either they eat the couple of bucks difference in plastic prices, or lose everything from the order.</p>

<p>As you can imagine, Dell chose the latter. Even though my order was &#8220;in production&#8221; she still allowed me to cancel it. I asked if I would get an email about it, she had no idea what I meant. Finally she said that my order status page would be updated. At the end of the call she asked for my email, I told them that they had it. She said they wanted to update it. I told them my email was firstname at lastname dot net.  She didn&#8217;t get it. So I spelled it out p-a-t-r-i-c-k-@-w-a-g-s-t-r-o-m-.-n-e-t.  She explained that my email address should end in hotmail.com or gmail.com. At this point I wanted to cry. I asked them what they had, she read off patrick@wagstrom.net and insisted that it could not be a valid email address. Just shoot me. I thanked her for her time, informed her that the information was correct and hung up.</p>

<p>Five minutes later I had placed an order for a <a href="http://www.newegg.com/Product/Product.aspx?Item=N82E16883103237">larger, faster, and slightly noisier machine from NewEgg</a>. For $200 in savings and not having to deal with Dell, I can deal with a little bit of noise. Unfortunately, the full review won&#8217;t arrive until the end of March when I&#8217;m back in Minneapolis.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/weblog/2010/02/13/what-qualifies-as-an-open-source-project/">What Qualifies as an Open Source Project?</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-02-13T21:26:14-05:00" pubdate data-updated="true">Feb 13<span>th</span>, 2010</time>
        
        
      </p>
    
  </header>


  <div class="entry-content"><p>I spent the last few days at the <a href="http://foss2010.isr.uci.edu/">FOSS2010 Workshop</a> in Irvine, CA.  It&#8217;s an interesting little workshop that brought together some of the best minds in Open Source research from academia, industry, and practice.  The goal was to develop a roadmap for the future of Open Source research.</p>

<p>One issue that constantly comes up is how many Open Source projects exist.  People most often point to <a href="http://sourceforge.net/">SourceForge</a> as an indicator of success, with it&#8217;s claim on 230,000 projects and more than 2 million users.  However, how many of those are really projects.</p>

<p>First, lets look at activity on SourceForge.  It&#8217;s about halfway through the day on Saturday, and according to the home page here&#8217;s a summary of Today&#8217;s activity:</p>

  <figure class='center'>
        <img src="/weblog/media/2010/02/SourceForgeDailyStats.png">
        <figcaption>Activity as of Noon PST on a Saturday </figcaption>
    </figure>


<p>If there are actually 230,000 active projects this amount is laughable.  I&#8217;ll be generous and say that bug tracking activity is less on a Saturday, so we assume that the 12 hours of data represent 1/1,000 of yearly activity, we&#8217;re getting less than three bugs per project a year.</p>

<p>I polled some of the other folks at the workshop for a definition of a project and I think we&#8217;ve gotten a pretty good idea. First, there is a selection of general project process attributes:</p>

<ul>
<li>Code available under an Open Source license</li>
<li>Publicly accessible web page, bug trackers, mailings lists, and version control</li>
<li>Governance model that allows outside contribution</li>
</ul>


<p>The license is actually the only item that is necessary to call a project Open Source, while publicly accessible collaboration resources and a governance model that allows for participation are conditions that are required for any sort of community to emerge.  However, under these terms it still is possible to have a project that is run by a single person and isn&#8217;t really open.  I can still create a project, release it under an Open Source license, register it on SourceForge, and say I accept contributions, but it won&#8217;t really be Open Source in most people&#8217;s definition of the words.</p>

<p>After talking to various other quite intelligent people within the community I&#8217;d like to propose the following criteria for calling a project truly Open Source:</p>

<ul>
<li>At least three different contributors</li>
<li>Code that can be compiled and run by someone with only moderate skill in the field and without significant external resources</li>
<li>A social process that not only allows contribution, but actively mentors new developers</li>
<li>Active participation by individuals who write no code</li>
</ul>


<p>I&#8217;ll go over each of these criteria and explain why they&#8217;re necessary for a first cut of determining whether or not a project is truly Open Source.</p>

<p>One of the key elements of Open Source development is that it is a collaborative effort by multiple developers.  Advantages include utilizing the expertise of each of the different developers and having many developers looking over the code to ensure to identify bugs.  If a project is just one or two people then it is unlikely that there is always enough overlap of individuals examining code.  Furthermore, it&#8217;s unlikely that the strategy process for designing and developing new features needs to be collaborative at all.  Fortunately, this is something that can be easily ascertained through automated methods when mining software communities.</p>

<p>The next requirement is that the project actually be able to compile by people of moderate skill in the field.  This is important because not everyone in the field of interest is going to be an expert.  If you require everyone to be an expert then the community will have trouble growing.  Requiring expensive libraries or exotic compilers has a similar effect and dramatically limits the pool of individuals.  It also may signify that the community really isn&#8217;t interested in harness the resources of an open community.  This raises some interesting questions about existing projects, for example, VISTA is a widely used system for managing hospital infrastructure from the Veterans Administration of the United States, but it written in MUMPS, a language that few people know and with even fewer compilers (I&#8217;m aware that in the strictest sense VISTA isn&#8217;t Open Source anyway, as the core is public domain, but we&#8217;ll ignore that for now).  How does this compare to open source code designed to run on Oracle&#8217;s high end databases?  I don&#8217;t have a clear answer, but when weighing projects it&#8217;s something to be aware of.</p>

<p>Next up is a social process that mentors new developers.  Sadly this is one place where many Open Source projects end up falling flat.  For example, GLIBC under the iron hand of Ulrich Drepper fails this category.  When dealing with potential future developers, it&#8217;s necessary to actively ensure they learn the process.  This includes simple things such as helping developers understand the process roadmap, explaining why bugs are rejected or marked as dupes, and responding to users on mailing lists in a gentle manner.  Now clearly, at some point projects need to put some of the impetus for learning on the potential community members or we&#8217;ll end up with hundreds of Bowie J. Poags, but I&#8217;d imagine for every Bowie you&#8217;ll get a couple of genuinely helpful developers.</p>

<p>The final issue is obtaining contributions from individuals who don&#8217;t write code.  For a long time there has been a perception that the code is all that really matters.  This was reinforced through some early writing such as the Cathedral and the Bazaar and misinterpretations of Lessig&#8217;s Code.  The most successful projects all have numerous individuals who write no code, instead they write documentation, create art, support users on the mailing lists and chat channels, and act as general promoters of the software across all media. The fact of the matter is that although I know many skilled coders who may excel in some of these additional areas, they can&#8217;t do it all alone.  Without these other individuals, you don&#8217;t really have an Open Source project.</p>

<p>I don&#8217;t claim that these criteria are perfect for identifying &#8220;true&#8221; Open Source projects, but they do help to ensure that projects at least have some of the key elements of what is generally considered to be Open Source and have a chance of being successful. I also don&#8217;t see this as competing with something like Tony Wasserman&#8217;s <a href="http://www.openbrr.org/">Open BRR</a>, rather, for individuals researching Open Source they should be a guideline for identifying projects that will be interesting and exhibit the behaviors that make Open Source interesting to study in the first place.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/weblog/2010/02/04/command-line-updating-pages-on-google-sites/">Command Line Updating Pages on Google Sites</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-02-04T21:38:28-05:00" pubdate data-updated="true">Feb 4<span>th</span>, 2010</time>
        
        
      </p>
    
  </header>


  <div class="entry-content"><p>About eighteen months ago I migrated <a href="http://academic.patrick.wagstrom.net/">my academic web pages</a> away from a self hosted solution on a Linux box in my living room to <a href="http://sites.google.com/">Google Sites</a>.  Mainly this was done because I was applying for jobs and wanted to make sure that the site would be reliable.  But although I came for the reliability, I stayed for the features.</p>

<p>It&#8217;s true that Google Sites is somewhat limiting in what you can do.  You can&#8217;t do fun stuff with <a href="http://jquery.com/">jQuery</a> and highly customized CSS is verboten.  It&#8217;s not going to work for someone who needs to share a design portfolio.  However, for an academic it works really well.  Basically, I need a set of pages about <a href="http://academic.patrick.wagstrom.net/">my research</a>, <a href="http://academic.patrick.wagstrom.net/publications">copies of my papers</a> and <a href="http://academic.patrick.wagstrom.net/presentations">presentations</a>, and various forms of <a href="http://academic.patrick.wagstrom.net/resume">my résumé</a> and <a href="http://academic.patrick.wagstrom.net/cv">cv</a>.  These are all typically boring pages that can be created with some simple HTML.  Google Sites manages that and even helps them look good too.</p>

<p>At that time I also realized that I needed to be a bit more flexible in how I handled my resume and CV.  Up until this point I had a highly customized LaTeX file that generated a very pretty PDF.  The beauty was only skin deep, underneath the PDF it was ugly, difficult to maintain, and if I wanted to paste portions of the document in to an email or someone requested a word document version, I was out of luck.</p>

<p>At the time I still hadn&#8217;t gotten <a href="http://patrick.wagstrom.net/weblog/2009/11/25/shutting-down-pennave/">my head on straight regarding how XML should never be used by humans</a>, so I chose the <a href="http://xmlresume.sourceforge.net/">XML Résumé Library</a>, an Open Source package that hasn&#8217;t been updated in a couple of years.  The library consists of an XML DTD that defines elements of a resume and a set of XSLT files that translate your resume into various formats, including text, html, and FO.  I can then use the FO files to generate PDF, DOCX, and ODT files.  Simple enough. Now I have a single source document with a Makefile that compiles the file into both my résumé and cv.</p>

<p>The problem is that I provide each document in five different formats, which means that I needed to upload 10 documents every time that I changed something.  This was not ideal at all.</p>

<p>Luckily, Google is in the process of making open APIs for all of their tools and last September they finally released the <a href="http://code.google.com/apis/sites/">Google Sites API</a>.  It still isn&#8217;t 100% complete, but with the <a href="http://code.google.com/p/gdata-python-client/">2.0.7 release of the python libraries</a> it is finally to the point where the python library is suitable for updating documents.</p>

<p>I whipped up a simple little python script that uploads files from the command line to Google Sites.  It only works with documents that have previously been uploaded by hand, so in that sense, it only updates documents.  You can find <a href="http://gist.github.com/295408">site_uploader.py as a github gist</a> or it should be embedded below.</p>

<p>The script itself has only been tested on apps for domains and has a couple of mandatory options:</p>

<ul>
<li><strong>-s/&#8211;site</strong>: The name of the site to update.  This isn&#8217;t the URL, but the name in your admin panel for the site.</li>
<li><strong>-d/&#8211;domain</strong>: The domain name of your apps for domain setup.  I&#8217;m not certain what happens if you don&#8217;t include this because all of my sites are hosted through Apps for Domains.</li>
<li><strong>-u/&#8211;user</strong>: The username to use for accessing the Google Sites API.</li>
<li><strong>-p/&#8211;pass</strong>: The password for the user account. The sites API provides multiple different authentication methods.  For my own convenience I have my Makefile prompt me for a password with Zenity then invoke the script.  I&#8217;m on a laptop which means the chance of someone else seeing my password in the process list is pretty slim.</li>
<li><strong>ENTRY_ID</strong>: each document on your site has an entry_id that doesn&#8217;t change with updates.  Think of it like a UUID.</li>
<li><strong>NEW_DOCUMENT</strong>: the filename of the new document to store on Google sites.</li>
</ul>


<p>When you&#8217;re first getting started with sites_uploader you can also use the <strong>&#8211;list</strong> option to get a list of all the documents on the site and their entry_id values.  Here&#8217;s what a simple session might look like:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>patrick@wallaby$ python sites_uploader.py -s "dummy" -d "wagstrom.net" -u "patrick@wagstrom.net" -p "PASSWORD" --ssl --list
</span><span class='line'>    ["attachment.png", "attachment", "https://sites.google.com/feeds/content/wagstrom.net/dummy/9999384153430219999"]
</span><span class='line'>    ["Home", "webpage", "https://sites.google.com/feeds/content/wagstrom.net/dummy/9999953700077559999"]
</span><span class='line'>    ["files", "filecabinet", "https://sites.google.com/feeds/content/wagstrom.net/test/9999182398032899999"]
</span><span class='line'>    patrick@wallaby$ python sites_uploader.py -s "dummy" -d "wagstrom.net" -u "patrick@wagstrom.net" -p "PASSWORD" --ssl https://sites.google.com/feeds/content/wagstrom.net/dummy/9999953700077559999 home.html</span></code></pre></td></tr></table></div></figure>


<p>This examines the site &#8220;dummy&#8221; under &#8220;wagstrom.net&#8221; by first listing all the documents, of which there are three: a png file called &#8220;attachment.png&#8221;, a webpage called &#8220;home&#8221;, and a filecabinet called &#8220;files&#8221;.  We note the id of the webpage called &#8220;home&#8221; and wish to replace its content with that of home.html.  When an operation is successful it prints out nothing.</p>

<p>The beauty of using id&#8217;s is that they don&#8217;t change, so once you look them up and put them into your Makefile, you&#8217;ll never need to change them again.  The other nice thing about Google Sites is that it sanitizes your HTML, so you can feed it a complete HTML file and it is smart enough to just take the part that belongs in the body of the document.  Pretty neat stuff indeed.</p>

<p>The code for the tool should be pretty straight forward, but folks have questions feel free to email me and I&#8217;ll attempt to answer.</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/weblog/blog/page/3/">&larr; Older</a>
    
    <a href="/weblog/blog/archives">Blog Archives</a>
    
    <a class="next" href="/weblog/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/weblog/2012/05/10/static-bloggin/">Static Bloggin</a>
      </li>
    
      <li class="post">
        <a href="/weblog/2012/01/28/i-am-not-a-climatologist-and-neither-are-most-of-these-people/">I am not a climatologist, and neither are most of these people</a>
      </li>
    
      <li class="post">
        <a href="/weblog/2012/01/10/looking-for-summer-interns-in-the-software-technology-group-at-ibm-tj-watson-research-center/">Looking for Summer Interns in the Software Technology Group at IBM TJ Watson Research Center</a>
      </li>
    
      <li class="post">
        <a href="/weblog/2012/01/03/a-review-of-2011-personal-development-goals/">A Review of 2011 Personal Development Goals</a>
      </li>
    
      <li class="post">
        <a href="/weblog/2012/01/03/open-source-and-technology-predictions-for-2012/">Open Source and Technology Predictions for 2012</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/pridkett">@pridkett</a> on GitHub
  
  <script type="text/javascript">
    $.domReady(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'pridkett',
            count: 0,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/weblog/javascripts/github.js" type="text/javascript"> </script>
</section>


<section>
  <h1>Latest Tweets</h1>
  <ul id="tweets">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  <script type="text/javascript">
    $.domReady(function(){
      getTwitterFeed("pridkett", 4, false);
    });
  </script>
  <script src="/weblog/javascripts/twitter.js" type="text/javascript"> </script>
  
    <a href="http://twitter.com/pridkett" class="twitter-follow-button" data-show-count="false">Follow @pridkett</a>
  
</section>



<section class="googleplus">
  <h1>
    <a href="https://plus.google.com/102672530623465237388?rel=author">
      <img src="http://www.google.com/images/icons/ui/gprofile_button-32.png" width="32" height="32">
      Google+
    </a>
  </h1>
</section>



  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2012 - Patrick Wagstrom -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  





  <script type="text/javascript">
    (function() {
      var script = document.createElement('script'); script.type = 'text/javascript'; script.async = true;
      script.src = 'https://apis.google.com/js/plusone.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(script, s);
    })();
  </script>



  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
